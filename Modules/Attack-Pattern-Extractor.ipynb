{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dspy\n",
    "import utils\n",
    "import typing\n",
    "import os \n",
    "import json\n",
    "from dspy.teleprompt import MIPROv2\n",
    "\n",
    "from BasicHtmlToTextParser import BasicHtmlToTextParser\n",
    "from metrics import stixnet_f1, semantic_match_hungarian\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "from collections import defaultdict\n",
    "\n",
    "from pydantic import BaseModel, Field\n",
    "from pydantic_core import ValidationError\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "_ = load_dotenv(\"../.env\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "llama_3_1_8b_instruct_deepinfra = dspy.LM(model=\"openai/meta-llama/Meta-Llama-3.1-8B-Instruct\", api_key=os.environ.get(\"DEEPINFRA_API_KEY\"), base_url=\"https://api.deepinfra.com/v1/openai\", temperature=0.1, max_tokens=1024)\n",
    "\n",
    "llama_3_1_8b_instruct_no_cache_deepinfra = dspy.LM(model=\"openai/meta-llama/Meta-Llama-3.1-8B-Instruct\", api_key=os.environ.get(\"DEEPINFRA_API_KEY\"), base_url=\"https://api.deepinfra.com/v1/openai\", temperature=0.3, max_tokens=1024, cache=False, cache_in_memory=False)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "llama_3_1_70b_instruct_turbo_deepinfra = dspy.LM(model=\"openai/meta-llama/Meta-Llama-3.1-70B-Instruct-Turbo\", api_key=os.environ.get(\"DEEPINFRA_API_KEY\"), base_url=\"https://api.deepinfra.com/v1/openai\", temperature=0.1, max_tokens=1024)\n",
    "\n",
    "llama_3_1_70b_instruct_turbo_no_cache_deepinfra = dspy.LM(model=\"openai/meta-llama/Meta-Llama-3.1-70B-Instruct-Turbo\", api_key=os.environ.get(\"DEEPINFRA_API_KEY\"), base_url=\"https://api.deepinfra.com/v1/openai\", temperature=0.3, max_tokens=1024, cache=False, cache_in_memory=False)\n",
    "\n",
    "\n",
    "\n",
    "llama_3_2_3b_instruct_deepinfra = dspy.LM(model=\"openai/meta-llama/Llama-3.2-3B-Instruct\", api_key=os.environ.get(\"DEEPINFRA_API_KEY\"), base_url=\"https://api.deepinfra.com/v1/openai\", temperature=0.1, max_tokens=1024)\n",
    "\n",
    "llama_3_2_3b_instruct_no_cache_deepinfra = dspy.LM(model=\"openai/meta-llama/Llama-3.2-3B-Instruct\", api_key=os.environ.get(\"DEEPINFRA_API_KEY\"), base_url=\"https://api.deepinfra.com/v1/openai\", temperature=0.3, max_tokens=1024, cache=False, cache_in_memory=False)\n",
    "\n",
    "\n",
    "\n",
    "llama_3_2_1b_instruct_deepinfra = dspy.LM(model=\"openai/meta-llama/Llama-3.2-1B-Instruct\", api_key=os.environ.get(\"DEEPINFRA_API_KEY\"), base_url=\"https://api.deepinfra.com/v1/openai\", temperature=0.1, max_tokens=1024)\n",
    "\n",
    "llama_3_2_1b_instruct_no_cache_deepinfra = dspy.LM(model=\"openai/meta-llama/Llama-3.2-1B-Instruct\", api_key=os.environ.get(\"DEEPINFRA_API_KEY\"), base_url=\"https://api.deepinfra.com/v1/openai\", temperature=0.3, max_tokens=1024, cache=False, cache_in_memory=False)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# qwen \n",
    "qwen_2_5_7b_instruct_deepinfra = dspy.LM(model=\"openai/Qwen/Qwen2.5-7B-Instruct\", api_key=os.environ.get(\"DEEPINFRA_API_KEY\"), base_url=\"https://api.deepinfra.com/v1/openai\", temperature=0.1, max_tokens=1024)\n",
    "\n",
    "qwen_2_5_7b_instruct_no_cache_deepinfra = dspy.LM(model=\"openai/Qwen/Qwen2.5-7B-Instruct\", api_key=os.environ.get(\"DEEPINFRA_API_KEY\"), base_url=\"https://api.deepinfra.com/v1/openai\", temperature=0.3, max_tokens=1024, cache=False, cache_in_memory=False)\n",
    "\n",
    "\n",
    "qwen_2_5_72b_instruct_deepinfra = dspy.LM(model=\"openai/Qwen/Qwen2.5-72B-Instruct\", api_key=os.environ.get(\"DEEPINFRA_API_KEY\"), base_url=\"https://api.deepinfra.com/v1/openai\", temperature=0.1, max_tokens=1024)\n",
    "\n",
    "qwen_2_5_72b_instruct_no_cache_deepinfra = dspy.LM(model=\"openai/Qwen/Qwen2.5-72B-Instruct\", api_key=os.environ.get(\"DEEPINFRA_API_KEY\"), base_url=\"https://api.deepinfra.com/v1/openai\", temperature=0.3, max_tokens=1024, cache=False, cache_in_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47 100 total: 147 train-ratio: 0.3197278911564626 dev-ratio: 0.6802721088435374\n",
      "47 100 0.3197278911564626 0.6802721088435374\n"
     ]
    }
   ],
   "source": [
    "dataset = utils.get_dspy_examples_randomized(\"../LADDER-Dataset/\", BasicHtmlToTextParser(include_images=False), random_seed=1337)\n",
    "\n",
    "trainset, devset = utils.split_dataset(split_at=47, dataset=dataset)\n",
    "\n",
    "trainset, devset = utils.generate_all_attack_patterns_dataset(trainset), utils.generate_all_attack_patterns_dataset(devset)\n",
    "\n",
    "\n",
    "trainset_ids, devset_ids = [example.id for example in trainset], [example.id for example in devset]\n",
    "assert len(set(trainset_ids) & set(devset_ids)) == 0\n",
    "\n",
    "print(len(trainset), len(devset), len(trainset)/(len(trainset)+len(devset)), len(devset)/(len(trainset)+len(devset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SentenceTransformer(\"sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2\", token=os.environ.get(\"HF_API_KEY\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class triple(BaseModel):\n",
    "    source: str = Field(description=\"name of the STIX Domain Object (SDO)\")\n",
    "    source_type: typing.Literal[\"malware\", \"threat_actor\", \"campaign\", \"course_of_action\", \"indicator\", \"intrusion_set\"] = Field(description=\"type of the SDO\")\n",
    "\n",
    "    relationship: typing.Literal[\"uses\", \"mitigates\", \"indicates\"] = Field(description=\"STIX Relationship Object (SRO) that connects the source object with the attack_pattern\")\n",
    "\n",
    "    target_attack_pattern: str = Field(description=\"The attack-pattern exactly as written in the threat report (like a directly cited quote)\")\n",
    "    target_type: typing.Literal[\"attack_pattern\"] = Field(description=\"The tail of the triple is always of type attack_pattern\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def enforce_stix(attack_pattern_triples: typing.List[triple]):\n",
    "    filered_triples = []\n",
    "\n",
    "    for triple in attack_pattern_triples:\n",
    "        if triple.source_type == \"malware\":\n",
    "            if triple.relationship == \"uses\":\n",
    "                filered_triples.append(triple)\n",
    "        \n",
    "        # add more rules to ensure coorect relationships between objects \n",
    "        # for example: \n",
    "        # elif triple.source_type == \"indicator\": \n",
    "            # if triple.relationship == \"indicates\":\n",
    "                # filered_triples.append(triple)\n",
    "    return filered_triples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "PRECISION_STORE, RECALL_STORE, F1_STORE = [], [], []\n",
    "\n",
    "def metric(example, pred, trace=None): \n",
    "    # all_mentioned_malware = example.mentioned_malwares # this comes from the dataset and is not relevant for metric. pred does not have this value!\n",
    "\n",
    "    malwares_with_attack_patterns = set()\n",
    "    for triple in example.attack_pattern_triples: \n",
    "        malwares_with_attack_patterns.add(triple.source)\n",
    "\n",
    "    gold_malwares = [malware.lower() for malware in malwares_with_attack_patterns]\n",
    "    pred_malwares = list({triple.source.lower() for triple in pred.attack_pattern_triples})\n",
    "    malware_matches = list(set(gold_malwares) & set(pred_malwares))\n",
    "    \n",
    "   \n",
    "    gold_attack_patterns_by_malware = defaultdict(set)\n",
    "    for triple in example.attack_pattern_triples:\n",
    "        gold_attack_patterns_by_malware[triple.source.lower()].add(triple.target_attack_pattern.lower())\n",
    "\n",
    "    pred_attack_patterns_by_malware = defaultdict(set)\n",
    "    for triple in pred.attack_pattern_triples:\n",
    "        pred_attack_patterns_by_malware[triple.source.lower()].add(triple.target_attack_pattern.lower())\n",
    "\n",
    "    \n",
    "    total_tp, total_fp, total_fn = 0, 0, 0 \n",
    "\n",
    "    for malware in malware_matches: \n",
    "        gold_attack_patterns = gold_attack_patterns_by_malware.get(malware, list())\n",
    "        pred_attack_patterns = pred_attack_patterns_by_malware.get(malware, list())\n",
    "\n",
    "        tp, fp, fn = semantic_match_hungarian(pred_attack_patterns, gold_attack_patterns, model=model, threshold=0.8)\n",
    "\n",
    "        total_tp += tp\n",
    "        total_fp += fp\n",
    "        total_fn += fn\n",
    "\n",
    "\n",
    "    missing_malwares = set(gold_malwares) - set(pred_malwares)\n",
    "    for missing_malware in missing_malwares:\n",
    "        total_fn += len(gold_attack_patterns_by_malware.get(missing_malware, []))\n",
    "\n",
    "    extra_malwares = set(pred_malwares) - set(gold_malwares)\n",
    "    for extra_malware in extra_malwares:\n",
    "        total_fp += len(pred_attack_patterns_by_malware.get(extra_malware, []))\n",
    "\n",
    "\n",
    "    precision, recall, f1 = stixnet_f1(total_tp, total_fp, total_fn)\n",
    "\n",
    "    PRECISION_STORE.append(precision)\n",
    "    RECALL_STORE.append(recall)\n",
    "    F1_STORE.append(f1)\n",
    "\n",
    "    return f1\n",
    "\n",
    "\n",
    "\n",
    "for example in devset + trainset:\n",
    "    assert metric(example, example) == 1.0\n",
    "\n",
    "\n",
    "def save_and_evaluate(program: dspy.Predict, llm: dspy.LM, llm_no_cache: dspy.LM, llm_id: str, base_path: str, valset: typing.List[dspy.Example]):\n",
    "    # #################################################################################################\n",
    "    global PRECISION_STORE\n",
    "    global RECALL_STORE\n",
    "    global F1_STORE\n",
    "\n",
    "    PRECISION_STORE, RECALL_STORE, F1_STORE = [], [], []\n",
    "    # #################################################################################################\n",
    "    \n",
    "    retry_stats = []\n",
    "    for i, obj in enumerate(valset): \n",
    "        \n",
    "        print(f\"{i+1}/{len(valset)}\")\n",
    "\n",
    "        retries, max_retries = 0, 5\n",
    "        while True:\n",
    "            try: \n",
    "                print(f\"Retry {retries}/{max_retries}\")\n",
    "                if retries > 0:\n",
    "                    with dspy.settings.context(lm=llm_no_cache):\n",
    "                        attack_pattern_triples = program(**obj.inputs()).attack_pattern_triples\n",
    "                else:\n",
    "                    with dspy.settings.context(lm=llm):\n",
    "                        attack_pattern_triples = program(**obj.inputs()).attack_pattern_triples\n",
    "\n",
    "                # enforce_stix(attack_pattern_triples) # it does not care about this function call! \n",
    "                pred = dspy.Prediction(attack_pattern_triples=attack_pattern_triples)\n",
    "\n",
    "                f1 = metric(obj, pred)\n",
    "                retry_stats.append({\"finished\": True, \"retries\": retries})\n",
    "                print(f\"✔️ done with {retries} retries\")\n",
    "                break\n",
    "\n",
    "            except ValidationError as e:\n",
    "                retries += 1\n",
    "                if retries == max_retries:  \n",
    "                    retry_stats.append({\"finished\": False, \"retries\": retries})\n",
    "                    RECALL_STORE.append(0)\n",
    "                    PRECISION_STORE.append(0)\n",
    "                    F1_STORE.append(0)\n",
    "                    print(f\"❌ Failed after {retries} retries\")\n",
    "                    break\n",
    "                \n",
    "            except Exception as e: \n",
    "                retries += 1\n",
    "                if retries == max_retries:  \n",
    "                    retry_stats.append({\"finished\": False, \"retries\": retries})\n",
    "                    RECALL_STORE.append(0)\n",
    "                    PRECISION_STORE.append(0)\n",
    "                    F1_STORE.append(0)\n",
    "                    print(f\"❌ Failed after {retries} retries\")\n",
    "                    break    \n",
    "            \n",
    "    # store result\n",
    "    with open(f\"{base_path}/{llm_id}_precision.json\", \"w\") as fp:\n",
    "        json.dump(PRECISION_STORE, fp)\n",
    "\n",
    "    with open(f\"{base_path}/{llm_id}_recall.json\", \"w\") as fp:\n",
    "        json.dump(RECALL_STORE, fp)\n",
    "\n",
    "    with open(f\"{base_path}/{llm_id}_f1.json\", \"w\") as fp:\n",
    "        json.dump(F1_STORE, fp)\n",
    "\n",
    "    with open(f\"{base_path}/{llm_id}_retry_stats.json\", \"w\") as fp:\n",
    "        json.dump(retry_stats, fp)\n",
    "\n",
    "    return retry_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AttackPatternsExtractionSignature(dspy.Signature):\n",
    "    \"\"\"\n",
    "    You are a cyber threat intelligence expert and your task is to analyse and extract all meaningful and relevant Attack Patterns from the provided threat report. Your sepcific task is to extract triple (simplified structure: \"<source, relationship, attack_pattern/>\"). The extracted CTI will be used to populate a STIX-Bundle that is generated for this specific threat report. This means the source of every triple you extract need to be a STIX Domain Object (SDO), the relationship needs to be a STIX Relationship Object (SRO) and the tail is always needs to be an Attack-Pattern! \n",
    "    \n",
    "    The following triples are considered valid and conform to the STIX 2.1 specification. Only extract triples that match these rules: \n",
    "        1. <campaign, uses, attack_pattern/>     (additional context: This Relationship describes that attacks carried out as part of the Campaign typically use the related Attack Pattern.)\n",
    "        2. <course_of_action, mitigates, attack_pattern/>    (additional context: This Relationship describes that the Course of Action can mitigate (e.g. respond to a threat) the related Attack Pattern.)\n",
    "        3. <indicator, indicates, attack_pattern/>   (additional context: This Relationship describes that the Indicator can detect evidence of the related Attack Pattern.)\n",
    "        4. <intrusion_set, uses, attack_pattern/>    (additional context: This Relationship describes that attacks carried out as part of the Intrusion Set typically use the related Attack Pattern.)\n",
    "        5. <threat_actor, uses, attack_pattern/>     (additional context: This Relationship describes that attacks carried out as part of the Threat Actor typically use the related Attack Pattern.)\n",
    "        6. <malware, uses, attack_pattern/>  (additional context: This Relationship documents that this malware instance or family uses the attack pattern.)\n",
    "\n",
    "    *Example for \"<malware, uses, attack_pattern>\" based on one sentence*\n",
    "        1. The provided threat report contains the sentence: \"Nexus malware is an Android banking trojan promoted as a malware-as-a-service (MaaS) offering that can be used for account takeover (ATO) attacks.\" \n",
    "        2. You need to recognize the CTI that is contained in the sentence. In this specific example: The malware \"Nexus\" is using the Attack-Pattern \"account takeover (ATO)\".\n",
    "        3. Do this for the whole threat report and extract all triples to represent the contained CTI. \n",
    "        4. Follow the provided format_instructions to generate a valid and machine readable output.\n",
    "        \n",
    "    *Final hints*\n",
    "        - Make sure to stricly cite the Attack-Pattern word by word\n",
    "        - Consider mentioned_malwares, mentioned_threat_actors as hints for the source of the triples\n",
    "    \"\"\"\n",
    "    threat_report: str = dspy.InputField()\n",
    "    mentioned_malwares: typing.List[str] = dspy.InputField(desc=\"A list of malware names that are mentioned in the threat report\")\n",
    "    mentioned_threat_actors: typing.List[str] = dspy.InputField(desc=\"A list of threat actors that are mentioned in the threat report\")\n",
    "    attack_pattern_triples: typing.List[triple] = dspy.OutputField()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert False, \"ALL DONE\"\n",
    "\n",
    "BASE_PATH = \"./AttackPatternExtractor/Baseline\"\n",
    "mlflow.autolog()\n",
    "mlflow.set_experiment(BASE_PATH)\n",
    "\n",
    "to_do = [\n",
    "    (\"llama_3_2_1b_instruct\", llama_3_2_1b_instruct_deepinfra, llama_3_2_1b_instruct_no_cache_deepinfra), # done \n",
    "    (\"llama_3_2_3b_instruct\", llama_3_2_3b_instruct_deepinfra, llama_3_2_3b_instruct_no_cache_deepinfra), done\n",
    "    (\"llama_3_1_8b_instruct\", llama_3_1_8b_instruct_deepinfra, llama_3_1_8b_instruct_no_cache_deepinfra),\n",
    "    (\"llama_3_1_70b_instruct\", llama_3_1_70b_instruct_turbo_deepinfra, llama_3_1_70b_instruct_turbo_no_cache_deepinfra),\n",
    "    (\"qwen_2_5_7b_instruct\", qwen_2_5_7b_instruct_deepinfra, qwen_2_5_7b_instruct_no_cache_deepinfra),\n",
    "    (\"qwen_2_5_72b_instruct\", qwen_2_5_72b_instruct_deepinfra, qwen_2_5_72b_instruct_no_cache_deepinfra),\n",
    "]\n",
    "\n",
    "\n",
    "for llm_id, llm, llm_no_cache in to_do:\n",
    "    program = dspy.Predict(AttackPatternsExtractionSignature)\n",
    "    \n",
    "    retry_stats = save_and_evaluate(program=program, base_path=BASE_PATH, llm_id=llm_id, llm=llm, llm_no_cache=llm_no_cache, valset=devset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use for example vllm  https://github.com/vllm-project/vllm\n",
    "API_KEY = None\n",
    "BASE_URL = None\n",
    "\n",
    "qwen_2_5_1p5b_instruct_vllm = dspy.LM(\"openai/Qwen/Qwen2.5-1.5B-Instruct\",  api_key=API_KEY, base_url=BASE_URL, temperature=0.1, max_tokens=1024)\n",
    "qwen_2_5_1p5b_instruct_no_cache_vllm = dspy.LM(\"openai/Qwen/Qwen2.5-1.5B-Instruct\",  api_key=API_KEY, base_url=BASE_URL, temperature=0.3, max_tokens=1024, cache=False, cache_in_memory=False)\n",
    "\n",
    "\n",
    "qwen_2_5_3b_instruct_vllm = dspy.LM(model=\"openai/Qwen/Qwen2.5-3B-Instruct\", api_key=API_KEY, base_url=BASE_URL, temperature=0.1, max_tokens=1024)\n",
    "qwen_2_5_3b_instruct_no_cache_vllm = dspy.LM(model=\"openai/Qwen/Qwen2.5-3B-Instruct\", api_key=API_KEY, base_url=BASE_URL, temperature=0.3, max_tokens=1024, cache=False, cache_in_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert False, \"DONE\"\n",
    "\n",
    "to_do = [\n",
    "    (\"qwen_2_5_1p5b_instruct\", qwen_2_5_1p5b_instruct_vllm, qwen_2_5_1p5b_instruct_no_cache_vllm)\n",
    "]\n",
    "\n",
    "BASE_PATH = \"./AttackPatternExtractor/Baseline\"\n",
    "\n",
    "mlflow.autolog()\n",
    "mlflow.set_experiment(BASE_PATH)\n",
    "\n",
    "for llm_id, llm, llm_no_cache in to_do: \n",
    "    program = dspy.Predict(AttackPatternsExtractionSignature)\n",
    "\n",
    "    save_and_evaluate(program, llm, llm_no_cache, llm_id, base_path=BASE_PATH, valset=devset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert False, \"DONE\"\n",
    "\n",
    "to_do = [\n",
    "    (\"qwen_2_5_3b_instruct\", qwen_2_5_3b_instruct_vllm, qwen_2_5_3b_instruct_no_cache_vllm)\n",
    "]\n",
    "\n",
    "BASE_PATH = \"./AttackPatternExtractor/Baseline\"\n",
    "\n",
    "mlflow.autolog()\n",
    "mlflow.set_experiment(BASE_PATH)\n",
    "\n",
    "for llm_id, llm, llm_no_cache in to_do: \n",
    "    program = dspy.Predict(AttackPatternsExtractionSignature)\n",
    "    \n",
    "    save_and_evaluate(program=program, base_path=BASE_PATH, llm_id=llm_id, llm=llm, llm_no_cache=llm_no_cache, valset=devset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ZERO SHOT OPTIMIERUNG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "o1_optimizer_settings = dict(num_candidates = 10, max_bootstrapped_demos = 0, max_labeled_demos = 0, metric_threshold = None, init_temperature = 0.5, task_model = None, num_threads = 16, max_errors = 30, prompt_model=llama_3_1_70b_instruct_turbo_deepinfra, teacher_settings=dict(lm=llama_3_1_70b_instruct_turbo_deepinfra), auto=None)\n",
    "\n",
    "\n",
    "o1_compiler_settings = dict(num_trials = 30, minibatch = True, minibatch_size = 25, minibatch_full_eval_steps = 10, program_aware_proposer=True, data_aware_proposer=True, view_data_batch_size=10, tip_aware_proposer=True, fewshot_aware_proposer=True, requires_permission_to_run=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert False, \"already finished and optimizer steps are not cached!\"\n",
    "BASE_PATH = \"./AttackPatternExtractor/ZERO-O1\"\n",
    "# mlflow.autolog()\n",
    "# mlflow.set_experiment(BASE_PATH)\n",
    "\n",
    "\n",
    "to_do = [\n",
    "    (\"llama_3_2_1b_instruct\", llama_3_2_1b_instruct_deepinfra, llama_3_2_1b_instruct_no_cache_deepinfra),\n",
    "    (\"llama_3_2_3b_instruct\", llama_3_2_3b_instruct_deepinfra, llama_3_2_3b_instruct_no_cache_deepinfra),\n",
    "    (\"llama_3_1_8b_instruct\", llama_3_1_8b_instruct_deepinfra, llama_3_1_8b_instruct_no_cache_deepinfra),\n",
    "    (\"llama_3_1_70b_instruct\", llama_3_1_70b_instruct_turbo_deepinfra, llama_3_1_70b_instruct_turbo_no_cache_deepinfra),\n",
    "\n",
    "    (\"qwen_2_5_7b_instruct\", qwen_2_5_7b_instruct_deepinfra, qwen_2_5_7b_instruct_no_cache_deepinfra),\n",
    "    (\"qwen_2_5_72b_instruct\", qwen_2_5_72b_instruct_deepinfra, qwen_2_5_72b_instruct_no_cache_deepinfra), # tbd\n",
    "]\n",
    "\n",
    "\n",
    "for llm_id, llm, llm_no_cache in to_do: \n",
    "    default_program = dspy.Predict(AttackPatternsExtractionSignature)\n",
    "\n",
    "    o1_optimizer = MIPROv2(metric=metric, **o1_optimizer_settings)\n",
    "                    \n",
    "    with dspy.settings.context(lm=llm):\n",
    "        optimized_program = o1_optimizer.compile(student=default_program, trainset=trainset, valset=devset, **o1_compiler_settings)\n",
    "\n",
    "    # store program (cloudpickle)\n",
    "    optimized_program.save(f\"{BASE_PATH}/{llm_id}\", save_program=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert False, \"already finished and optimizer steps are not cached!\"\n",
    "\n",
    "\n",
    "BASE_PATH = \"./AttackPatternExtractor/ZERO-O1\"\n",
    "# mlflow.autolog()\n",
    "# mlflow.set_experiment(BASE_PATH)\n",
    "\n",
    "\n",
    "to_do = [\n",
    "    (\"qwen_2_5_1p5b_instruct\", qwen_2_5_1p5b_instruct_vllm, qwen_2_5_1p5b_instruct_no_cache_vllm)\n",
    "]\n",
    "\n",
    "\n",
    "for llm_id, llm, llm_no_cache in to_do: \n",
    "    default_program = dspy.Predict(AttackPatternsExtractionSignature)\n",
    "    \n",
    "    o1_optimizer = MIPROv2(metric=metric, **o1_optimizer_settings)\n",
    "                    \n",
    "    with dspy.settings.context(lm=llm):\n",
    "        optimized_program = o1_optimizer.compile(student=default_program, trainset=trainset, valset=devset, **o1_compiler_settings)\n",
    "\n",
    "    # store program (cloudpickle)\n",
    "    optimized_program.save(f\"{BASE_PATH}/{llm_id}\", save_program=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert False, \"already finished and optimizer steps are not cached!\"\n",
    "\n",
    "BASE_PATH = \"./AttackPatternExtractor/ZERO-O1\"\n",
    "\n",
    "\n",
    "to_do = [\n",
    "    (\"qwen_2_5_3b_instruct\", qwen_2_5_3b_instruct_vllm, qwen_2_5_3b_instruct_no_cache_vllm)\n",
    "]\n",
    "\n",
    "\n",
    "for llm_id, llm, llm_no_cache in to_do: \n",
    "    default_program = dspy.Predict(AttackPatternsExtractionSignature)\n",
    "    \n",
    "    o1_optimizer = MIPROv2(metric=metric, **o1_optimizer_settings)\n",
    "                    \n",
    "    with dspy.settings.context(lm=llm):\n",
    "        optimized_program = o1_optimizer.compile(student=default_program, trainset=trainset, valset=devset, **o1_compiler_settings)\n",
    "\n",
    "    # store program (cloudpickle)\n",
    "    optimized_program.save(f\"{BASE_PATH}/{llm_id}\", save_program=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "o2_optimizer_settings = dict(num_candidates = 25, max_bootstrapped_demos = 0, max_labeled_demos = 0, metric_threshold = None, init_temperature = 0.5, task_model = None, num_threads = 16, max_errors = 30, prompt_model=llama_3_1_70b_instruct_turbo_deepinfra, teacher_settings=dict(lm=llama_3_1_70b_instruct_turbo_deepinfra), auto=None)\n",
    "\n",
    "\n",
    "o2_compiler_settings = dict(num_trials = 50, minibatch = True, minibatch_size = 25, minibatch_full_eval_steps = 10, program_aware_proposer=True, data_aware_proposer=True, view_data_batch_size=10, tip_aware_proposer=True, fewshot_aware_proposer=True, requires_permission_to_run=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert False, \"already finished and optimizer steps are not cached!\"\n",
    "\n",
    "BASE_PATH = \"./AttackPatternExtractor/ZERO-O2\"\n",
    "\n",
    "to_do = [\n",
    "    (\"llama_3_2_1b_instruct\", llama_3_2_1b_instruct_deepinfra, llama_3_2_1b_instruct_no_cache_deepinfra),\n",
    "    (\"llama_3_2_3b_instruct\", llama_3_2_3b_instruct_deepinfra, llama_3_2_3b_instruct_no_cache_deepinfra),\n",
    "    (\"llama_3_1_8b_instruct\", llama_3_1_8b_instruct_deepinfra, llama_3_1_8b_instruct_no_cache_deepinfra),\n",
    "    (\"llama_3_1_70b_instruct\", llama_3_1_70b_instruct_turbo_deepinfra, llama_3_1_70b_instruct_turbo_no_cache_deepinfra),\n",
    "\n",
    "    (\"qwen_2_5_7b_instruct\", qwen_2_5_7b_instruct_deepinfra, qwen_2_5_7b_instruct_no_cache_deepinfra),\n",
    "    (\"qwen_2_5_72b_instruct\", qwen_2_5_72b_instruct_deepinfra, qwen_2_5_72b_instruct_no_cache_deepinfra),\n",
    "]\n",
    "\n",
    "\n",
    "for llm_id, llm, llm_no_cache in to_do: \n",
    "    default_program = dspy.Predict(AttackPatternsExtractionSignature)\n",
    "\n",
    "    o2_optimizer = MIPROv2(metric=metric, **o2_optimizer_settings)\n",
    "                    \n",
    "    with dspy.settings.context(lm=llm):\n",
    "        optimized_program = o2_optimizer.compile(student=default_program, trainset=trainset, valset=devset, **o2_compiler_settings)\n",
    "\n",
    "    # store program (cloudpickle)\n",
    "    optimized_program.save(f\"{BASE_PATH}/{llm_id}\", save_program=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert False, \"already finished and optimizer steps are not cached!\"\n",
    "\n",
    "\n",
    "BASE_PATH = \"./AttackPatternExtractor/ZERO-O2\"\n",
    "\n",
    "\n",
    "to_do = [\n",
    "    (\"qwen_2_5_1p5b_instruct\", qwen_2_5_1p5b_instruct_vllm, qwen_2_5_1p5b_instruct_no_cache_vllm)\n",
    "]\n",
    "\n",
    "\n",
    "for llm_id, llm, llm_no_cache in to_do: \n",
    "    # default_program = AttackPatternExtractionModule(llm=llm, llm_no_cache=llm_no_cache, attack_pattern_extractor_program=dspy.Predict(AttackPatternsExtractionSignature), retry_stats=[])\n",
    "    default_program = dspy.Predict(AttackPatternsExtractionSignature)\n",
    "    \n",
    "    o2_optimizer = MIPROv2(metric=metric, **o2_optimizer_settings)\n",
    "                    \n",
    "    with dspy.settings.context(lm=llm):\n",
    "        optimized_program = o2_optimizer.compile(student=default_program, trainset=trainset, valset=devset, **o2_compiler_settings)\n",
    "\n",
    "    # store program (cloudpickle)\n",
    "    optimized_program.save(f\"{BASE_PATH}/{llm_id}\", save_program=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert False, \"already finished and optimizer steps are not cached!\"\n",
    "BASE_PATH = \"./AttackPatternExtractor/ZERO-O2\"\n",
    "\n",
    "\n",
    "to_do = [\n",
    "    (\"qwen_2_5_3b_instruct\", qwen_2_5_3b_instruct_vllm, qwen_2_5_3b_instruct_no_cache_vllm)\n",
    "]\n",
    "\n",
    "\n",
    "for llm_id, llm, llm_no_cache in to_do: \n",
    "    default_program = dspy.Predict(AttackPatternsExtractionSignature)\n",
    "    \n",
    "    o2_optimizer = MIPROv2(metric=metric, **o2_optimizer_settings)\n",
    "                    \n",
    "    with dspy.settings.context(lm=llm):\n",
    "        optimized_program = o2_optimizer.compile(student=default_program, trainset=trainset, valset=devset, **o2_compiler_settings)\n",
    "\n",
    "    # store program (cloudpickle)\n",
    "    optimized_program.save(f\"{BASE_PATH}/{llm_id}\", save_program=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FEW SHOT OPTIMIERUNG O1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "o1_optimizer_settings = dict(num_candidates = 10, max_bootstrapped_demos = 1, max_labeled_demos = 2, metric_threshold = None, init_temperature = 0.5, task_model = None, num_threads = 42, max_errors = 100, prompt_model=llama_3_1_70b_instruct_turbo_deepinfra, teacher_settings=dict(lm=llama_3_1_70b_instruct_turbo_deepinfra), auto=None)\n",
    "\n",
    "\n",
    "o1_compiler_settings = dict(num_trials = 30, minibatch = True, minibatch_size = 25, minibatch_full_eval_steps = 10, program_aware_proposer=True, data_aware_proposer=True, view_data_batch_size=10, tip_aware_proposer=True, fewshot_aware_proposer=True, requires_permission_to_run=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert False, \"already finished and optimizer steps are not cached!\"\n",
    "BASE_PATH = \"./AttackPatternExtractor/FS-O1\"\n",
    "\n",
    "\n",
    "to_do = [\n",
    "    (\"llama_3_2_1b_instruct\", llama_3_2_1b_instruct_deepinfra, llama_3_2_1b_instruct_no_cache_deepinfra),\n",
    "    (\"llama_3_2_3b_instruct\", llama_3_2_3b_instruct_deepinfra, llama_3_2_3b_instruct_no_cache_deepinfra),\n",
    "    (\"llama_3_1_8b_instruct\", llama_3_1_8b_instruct_deepinfra, llama_3_1_8b_instruct_no_cache_deepinfra),\n",
    "    (\"llama_3_1_70b_instruct\", llama_3_1_70b_instruct_turbo_deepinfra, llama_3_1_70b_instruct_turbo_no_cache_deepinfra),\n",
    "\n",
    "    (\"qwen_2_5_7b_instruct\", qwen_2_5_7b_instruct_deepinfra, qwen_2_5_7b_instruct_no_cache_deepinfra),\n",
    "    (\"qwen_2_5_72b_instruct\", qwen_2_5_72b_instruct_deepinfra, qwen_2_5_72b_instruct_no_cache_deepinfra),\n",
    "]\n",
    "\n",
    "\n",
    "for llm_id, llm, llm_no_cache in to_do: \n",
    "    default_program = dspy.Predict(AttackPatternsExtractionSignature)\n",
    "\n",
    "    o1_optimizer = MIPROv2(metric=metric, **o1_optimizer_settings)\n",
    "                    \n",
    "    with dspy.settings.context(lm=llm):\n",
    "        optimized_program = o1_optimizer.compile(student=default_program, trainset=trainset, valset=devset, **o1_compiler_settings)\n",
    "\n",
    "    # store program (cloudpickle)\n",
    "    optimized_program.save(f\"{BASE_PATH}/{llm_id}\", save_program=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert False, \"already finished and optimizer steps are not cached!\"\n",
    "\n",
    "\n",
    "BASE_PATH = \"./AttackPatternExtractor/FS-O1\"\n",
    "\n",
    "\n",
    "to_do = [\n",
    "    (\"qwen_2_5_1p5b_instruct\", qwen_2_5_1p5b_instruct_vllm, qwen_2_5_1p5b_instruct_no_cache_vllm)\n",
    "]\n",
    "\n",
    "\n",
    "for llm_id, llm, llm_no_cache in to_do: \n",
    "    default_program = dspy.Predict(AttackPatternsExtractionSignature)\n",
    "    \n",
    "    o1_optimizer = MIPROv2(metric=metric, **o1_optimizer_settings)\n",
    "                    \n",
    "    with dspy.settings.context(lm=llm):\n",
    "        optimized_program = o1_optimizer.compile(student=default_program, trainset=trainset, valset=devset, **o1_compiler_settings)\n",
    "\n",
    "    # store program (cloudpickle)\n",
    "    optimized_program.save(f\"{BASE_PATH}/{llm_id}\", save_program=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert False, \"already finished and optimizer steps are not cached!\"\n",
    "\n",
    "BASE_PATH = \"./AttackPatternExtractor/FS-O1\"\n",
    "\n",
    "to_do = [\n",
    "    (\"qwen_2_5_3b_instruct\", qwen_2_5_3b_instruct_vllm, qwen_2_5_3b_instruct_no_cache_vllm)\n",
    "]\n",
    "\n",
    "\n",
    "for llm_id, llm, llm_no_cache in to_do: \n",
    "    default_program = dspy.Predict(AttackPatternsExtractionSignature)\n",
    "    \n",
    "    o1_optimizer = MIPROv2(metric=metric, **o1_optimizer_settings)\n",
    "                    \n",
    "    with dspy.settings.context(lm=llm):\n",
    "        optimized_program = o1_optimizer.compile(student=default_program, trainset=trainset, valset=devset, **o1_compiler_settings)\n",
    "\n",
    "    # store program (cloudpickle)\n",
    "    optimized_program.save(f\"{BASE_PATH}/{llm_id}\", save_program=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FEW SHOT OPTIMIERUNG O2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "o2_optimizer_settings = dict(num_candidates = 25, max_bootstrapped_demos = 1, max_labeled_demos = 2, metric_threshold = None, init_temperature = 0.5, task_model = None, num_threads = 16, max_errors = 100, prompt_model=llama_3_1_70b_instruct_turbo_deepinfra, teacher_settings=dict(lm=llama_3_1_70b_instruct_turbo_deepinfra), auto=None)\n",
    "\n",
    "\n",
    "o2_compiler_settings = dict(num_trials = 50, minibatch = True, minibatch_size = 25, minibatch_full_eval_steps = 10, program_aware_proposer=True, data_aware_proposer=True, view_data_batch_size=10, tip_aware_proposer=True, fewshot_aware_proposer=True, requires_permission_to_run=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert False, \"already finished and optimizer steps are not cached!\"\n",
    "BASE_PATH = \"./AttackPatternExtractor/FS-O2\"\n",
    "\n",
    "to_do = [\n",
    "    (\"llama_3_2_1b_instruct\", llama_3_2_1b_instruct_deepinfra, llama_3_2_1b_instruct_no_cache_deepinfra),\n",
    "    (\"llama_3_2_3b_instruct\", llama_3_2_3b_instruct_deepinfra, llama_3_2_3b_instruct_no_cache_deepinfra),\n",
    "    (\"llama_3_1_8b_instruct\", llama_3_1_8b_instruct_deepinfra, llama_3_1_8b_instruct_no_cache_deepinfra),\n",
    "    (\"llama_3_1_70b_instruct\", llama_3_1_70b_instruct_turbo_deepinfra, llama_3_1_70b_instruct_turbo_no_cache_deepinfra),\n",
    "\n",
    "    (\"qwen_2_5_7b_instruct\", qwen_2_5_7b_instruct_deepinfra, qwen_2_5_7b_instruct_no_cache_deepinfra),\n",
    "    (\"qwen_2_5_72b_instruct\", qwen_2_5_72b_instruct_deepinfra, qwen_2_5_72b_instruct_no_cache_deepinfra),\n",
    "]\n",
    "\n",
    "\n",
    "for llm_id, llm, llm_no_cache in to_do: \n",
    "    default_program = dspy.Predict(AttackPatternsExtractionSignature)\n",
    "\n",
    "    o2_optimizer = MIPROv2(metric=metric, **o2_optimizer_settings)\n",
    "                    \n",
    "    with dspy.settings.context(lm=llm):\n",
    "        optimized_program = o2_optimizer.compile(student=default_program, trainset=trainset, valset=devset, **o2_compiler_settings)\n",
    "\n",
    "    # store program (cloudpickle)\n",
    "    optimized_program.save(f\"{BASE_PATH}/{llm_id}\", save_program=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert False, \"already finished and optimizer steps are not cached!\"\n",
    "\n",
    "\n",
    "BASE_PATH = \"./AttackPatternExtractor/FS-O2\"\n",
    "\n",
    "\n",
    "to_do = [\n",
    "    (\"qwen_2_5_1p5b_instruct\", qwen_2_5_1p5b_instruct_vllm, qwen_2_5_1p5b_instruct_no_cache_vllm)\n",
    "]\n",
    "\n",
    "\n",
    "for llm_id, llm, llm_no_cache in to_do: \n",
    "    default_program = dspy.Predict(AttackPatternsExtractionSignature)\n",
    "    \n",
    "    o2_optimizer = MIPROv2(metric=metric, **o2_optimizer_settings)\n",
    "                    \n",
    "    with dspy.settings.context(lm=llm):\n",
    "        optimized_program = o2_optimizer.compile(student=default_program, trainset=trainset, valset=devset, **o2_compiler_settings)\n",
    "\n",
    "    # store program (cloudpickle)\n",
    "    optimized_program.save(f\"{BASE_PATH}/{llm_id}\", save_program=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert False, \"already finished and optimizer steps are not cached!\"\n",
    "\n",
    "BASE_PATH = \"./AttackPatternExtractor/FS-O2\"\n",
    "\n",
    "\n",
    "to_do = [\n",
    "    (\"qwen_2_5_3b_instruct\", qwen_2_5_3b_instruct_vllm, qwen_2_5_3b_instruct_no_cache_vllm)\n",
    "]\n",
    "\n",
    "\n",
    "for llm_id, llm, llm_no_cache in to_do: \n",
    "    default_program = dspy.Predict(AttackPatternsExtractionSignature)\n",
    "    \n",
    "    o2_optimizer = MIPROv2(metric=metric, **o2_optimizer_settings)\n",
    "                    \n",
    "    with dspy.settings.context(lm=llm):\n",
    "        optimized_program = o2_optimizer.compile(student=default_program, trainset=trainset, valset=devset, **o2_compiler_settings)\n",
    "\n",
    "    # store program (cloudpickle)\n",
    "    optimized_program.save(f\"{BASE_PATH}/{llm_id}\", save_program=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EVALUATION OF THE OPTIMIZED PROGRAMS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert False, \"already finished and optimizer steps are not cached!\"\n",
    "BASE_PATH = \"./AttackPatternExtractor/ZERO-O1\"\n",
    "\n",
    "\n",
    "to_do = [\n",
    "    (\"llama_3_2_1b_instruct\", llama_3_2_1b_instruct_deepinfra, llama_3_2_1b_instruct_no_cache_deepinfra),\n",
    "    (\"llama_3_2_3b_instruct\", llama_3_2_3b_instruct_deepinfra, llama_3_2_3b_instruct_no_cache_deepinfra),\n",
    "    (\"llama_3_1_8b_instruct\", llama_3_1_8b_instruct_deepinfra, llama_3_1_8b_instruct_no_cache_deepinfra),\n",
    "    (\"llama_3_1_70b_instruct\", llama_3_1_70b_instruct_turbo_deepinfra, llama_3_1_70b_instruct_turbo_no_cache_deepinfra),\n",
    "\n",
    "    (\"qwen_2_5_7b_instruct\", qwen_2_5_7b_instruct_deepinfra, qwen_2_5_7b_instruct_no_cache_deepinfra),\n",
    "    (\"qwen_2_5_72b_instruct\", qwen_2_5_72b_instruct_deepinfra, qwen_2_5_72b_instruct_no_cache_deepinfra),\n",
    "]\n",
    "\n",
    "\n",
    "for llm_id, llm, llm_no_cache in to_do: \n",
    "    program = dspy.load(f\"{BASE_PATH}/{llm_id}\")\n",
    "    save_and_evaluate(program, llm, llm_no_cache, llm_id, base_path=BASE_PATH, valset=devset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert False, \"already finished and optimizer steps are not cached!\"\n",
    "\n",
    "BASE_PATH = \"./AttackPatternExtractor/ZERO-O1\"\n",
    "mlflow.autolog()\n",
    "mlflow.set_experiment(BASE_PATH)\n",
    "\n",
    "to_do = [\n",
    "    (\"qwen_2_5_1p5b_instruct\", qwen_2_5_1p5b_instruct_vllm, qwen_2_5_1p5b_instruct_no_cache_vllm)\n",
    "]\n",
    "\n",
    "\n",
    "for llm_id, llm, llm_no_cache in to_do:\n",
    "    program = dspy.load(f\"{BASE_PATH}/{llm_id}\")\n",
    "    save_and_evaluate(program, llm, llm_no_cache, llm_id, base_path=BASE_PATH, valset=devset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert False, \"already finished and optimizer steps are not cached!\"\n",
    "BASE_PATH = \"./AttackPatternExtractor/ZERO-O1\"\n",
    "\n",
    "\n",
    "to_do = [\n",
    "    (\"qwen_2_5_3b_instruct\", qwen_2_5_3b_instruct_vllm, qwen_2_5_3b_instruct_no_cache_vllm)\n",
    "]\n",
    "\n",
    "\n",
    "for llm_id, llm, llm_no_cache in to_do: \n",
    "    program = dspy.load(f\"{BASE_PATH}/{llm_id}\")\n",
    "    save_and_evaluate(program, llm, llm_no_cache, llm_id, base_path=BASE_PATH, valset=devset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert False, \"already finished and optimizer steps are not cached!\"\n",
    "BASE_PATH = \"./AttackPatternExtractor/ZERO-O2\"\n",
    "\n",
    "\n",
    "to_do = [\n",
    "    (\"llama_3_2_1b_instruct\", llama_3_2_1b_instruct_deepinfra, llama_3_2_1b_instruct_no_cache_deepinfra),\n",
    "    (\"llama_3_2_3b_instruct\", llama_3_2_3b_instruct_deepinfra, llama_3_2_3b_instruct_no_cache_deepinfra),\n",
    "    (\"llama_3_1_8b_instruct\", llama_3_1_8b_instruct_deepinfra, llama_3_1_8b_instruct_no_cache_deepinfra),\n",
    "    (\"llama_3_1_70b_instruct\", llama_3_1_70b_instruct_turbo_deepinfra, llama_3_1_70b_instruct_turbo_no_cache_deepinfra),\n",
    "\n",
    "    (\"qwen_2_5_7b_instruct\", qwen_2_5_7b_instruct_deepinfra, qwen_2_5_7b_instruct_no_cache_deepinfra),\n",
    "    (\"qwen_2_5_72b_instruct\", qwen_2_5_72b_instruct_deepinfra, qwen_2_5_72b_instruct_no_cache_deepinfra),\n",
    "]\n",
    "\n",
    "\n",
    "\n",
    "for llm_id, llm, llm_no_cache in to_do: \n",
    "    program = dspy.load(f\"{BASE_PATH}/{llm_id}\")\n",
    "    save_and_evaluate(program, llm, llm_no_cache, llm_id, base_path=BASE_PATH, valset=devset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert False, \"already finished and optimizer steps are not cached!\"\n",
    "BASE_PATH = \"./AttackPatternExtractor/ZERO-O2\"\n",
    "\n",
    "\n",
    "to_do = [\n",
    "    (\"qwen_2_5_1p5b_instruct\", qwen_2_5_1p5b_instruct_vllm, qwen_2_5_1p5b_instruct_no_cache_vllm)\n",
    "]\n",
    "\n",
    "for llm_id, llm, llm_no_cache in to_do: \n",
    "    program = dspy.load(f\"{BASE_PATH}/{llm_id}\")\n",
    "    save_and_evaluate(program, llm, llm_no_cache, llm_id, base_path=BASE_PATH, valset=devset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert False, \"already finished and optimizer steps are not cached!\"\n",
    "\n",
    "BASE_PATH = \"./AttackPatternExtractor/ZERO-O2\"\n",
    "\n",
    "\n",
    "to_do = [\n",
    "    (\"qwen_2_5_3b_instruct\", qwen_2_5_3b_instruct_vllm, qwen_2_5_3b_instruct_no_cache_vllm)\n",
    "]\n",
    "\n",
    "\n",
    "for llm_id, llm, llm_no_cache in to_do: \n",
    "    program = dspy.load(f\"{BASE_PATH}/{llm_id}\")\n",
    "    save_and_evaluate(program, llm, llm_no_cache, llm_id, base_path=BASE_PATH, valset=devset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FEW SHOT Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert False, \"already finished and optimizer steps are not cached!\"\n",
    "BASE_PATH = \"./AttackPatternExtractor/FS-O1\"\n",
    "\n",
    "\n",
    "to_do = [\n",
    "    (\"llama_3_2_1b_instruct\", llama_3_2_1b_instruct_deepinfra, llama_3_2_1b_instruct_no_cache_deepinfra),\n",
    "    (\"llama_3_2_3b_instruct\", llama_3_2_3b_instruct_deepinfra, llama_3_2_3b_instruct_no_cache_deepinfra),\n",
    "    (\"llama_3_1_8b_instruct\", llama_3_1_8b_instruct_deepinfra, llama_3_1_8b_instruct_no_cache_deepinfra),\n",
    "    (\"llama_3_1_70b_instruct\", llama_3_1_70b_instruct_turbo_deepinfra, llama_3_1_70b_instruct_turbo_no_cache_deepinfra),\n",
    "\n",
    "    (\"qwen_2_5_7b_instruct\", qwen_2_5_7b_instruct_deepinfra, qwen_2_5_7b_instruct_no_cache_deepinfra),\n",
    "    (\"qwen_2_5_72b_instruct\", qwen_2_5_72b_instruct_deepinfra, qwen_2_5_72b_instruct_no_cache_deepinfra),\n",
    "]\n",
    "\n",
    "\n",
    "\n",
    "for llm_id, llm, llm_no_cache in to_do: \n",
    "    program = dspy.load(f\"{BASE_PATH}/{llm_id}\")\n",
    "    save_and_evaluate(program, llm, llm_no_cache, llm_id, base_path=BASE_PATH, valset=devset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert False, \"already finished and optimizer steps are not cached!\"\n",
    "\n",
    "BASE_PATH = \"./AttackPatternExtractor/FS-O1\"\n",
    "\n",
    "\n",
    "to_do = [\n",
    "    (\"qwen_2_5_1p5b_instruct\", qwen_2_5_1p5b_instruct_vllm, qwen_2_5_1p5b_instruct_no_cache_vllm)\n",
    "]\n",
    "\n",
    "\n",
    "for llm_id, llm, llm_no_cache in to_do: \n",
    "    program = dspy.load(f\"{BASE_PATH}/{llm_id}\")\n",
    "    save_and_evaluate(program, llm, llm_no_cache, llm_id, base_path=BASE_PATH, valset=devset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert False, \"already finished and optimizer steps are not cached!\"\n",
    "\n",
    "BASE_PATH = \"./AttackPatternExtractor/FS-O1\"\n",
    "\n",
    "\n",
    "to_do = [\n",
    "    (\"qwen_2_5_3b_instruct\", qwen_2_5_3b_instruct_vllm, qwen_2_5_3b_instruct_no_cache_vllm)\n",
    "]\n",
    "\n",
    "\n",
    "for llm_id, llm, llm_no_cache in to_do: \n",
    "    program = dspy.load(f\"{BASE_PATH}/{llm_id}\")\n",
    "    save_and_evaluate(program, llm, llm_no_cache, llm_id, base_path=BASE_PATH, valset=devset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert False, \"already finished and optimizer steps are not cached!\"\n",
    "BASE_PATH = \"./AttackPatternExtractor/FS-O2\"\n",
    "\n",
    "\n",
    "to_do = [\n",
    "    (\"llama_3_2_1b_instruct\", llama_3_2_1b_instruct_deepinfra, llama_3_2_1b_instruct_no_cache_deepinfra),\n",
    "    (\"llama_3_2_3b_instruct\", llama_3_2_3b_instruct_deepinfra, llama_3_2_3b_instruct_no_cache_deepinfra),\n",
    "    (\"llama_3_1_8b_instruct\", llama_3_1_8b_instruct_deepinfra, llama_3_1_8b_instruct_no_cache_deepinfra),\n",
    "    (\"llama_3_1_70b_instruct\", llama_3_1_70b_instruct_turbo_deepinfra, llama_3_1_70b_instruct_turbo_no_cache_deepinfra),\n",
    "\n",
    "    (\"qwen_2_5_7b_instruct\", qwen_2_5_7b_instruct_deepinfra, qwen_2_5_7b_instruct_no_cache_deepinfra),\n",
    "    (\"qwen_2_5_72b_instruct\", qwen_2_5_72b_instruct_deepinfra, qwen_2_5_72b_instruct_no_cache_deepinfra),\n",
    "]\n",
    "\n",
    "\n",
    "for llm_id, llm, llm_no_cache in to_do: \n",
    "    program = dspy.load(f\"{BASE_PATH}/{llm_id}\")\n",
    "    save_and_evaluate(program, llm, llm_no_cache, llm_id, base_path=BASE_PATH, valset=devset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert False, \"already finished and optimizer steps are not cached!\"\n",
    "BASE_PATH = \"./AttackPatternExtractor/FS-O2\"\n",
    "\n",
    "\n",
    "to_do = [\n",
    "    (\"qwen_2_5_1p5b_instruct\", qwen_2_5_1p5b_instruct_vllm, qwen_2_5_1p5b_instruct_no_cache_vllm)\n",
    "]\n",
    "\n",
    "\n",
    "for llm_id, llm, llm_no_cache in to_do: \n",
    "    program = dspy.load(f\"{BASE_PATH}/{llm_id}\")\n",
    "    save_and_evaluate(program, llm, llm_no_cache, llm_id, base_path=BASE_PATH, valset=devset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert False, \"already finished and optimizer steps are not cached!\"\n",
    "\n",
    "BASE_PATH = \"./AttackPatternExtractor/FS-O2\"\n",
    "\n",
    "\n",
    "to_do = [\n",
    "    (\"qwen_2_5_3b_instruct\", qwen_2_5_3b_instruct_vllm, qwen_2_5_3b_instruct_no_cache_vllm)\n",
    "]\n",
    "\n",
    "\n",
    "for llm_id, llm, llm_no_cache in to_do: \n",
    "    program = dspy.load(f\"{BASE_PATH}/{llm_id}\")\n",
    "    save_and_evaluate(program, llm, llm_no_cache, llm_id, base_path=BASE_PATH, valset=devset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
