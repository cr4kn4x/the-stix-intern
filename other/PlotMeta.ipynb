{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e0bf3a69",
   "metadata": {},
   "outputs": [],
   "source": [
    "import Modules.utils as utils\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "plt.rcParams.update({\n",
    "    \"pgf.texsystem\": \"pdflatex\",\n",
    "    \"font.family\": \"serif\",\n",
    "    \"text.usetex\": True,         \n",
    "    \"pgf.rcfonts\": False,\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d2a5027",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e2b0f29a",
   "metadata": {},
   "outputs": [],
   "source": [
    "malware_extractor_data = utils.load_json_files(\"./Modules/MalwareExtractor\", [\"Baseline\", \"ZERO-O1\", \"ZERO-O2\", \"FS-O1\", \"FS-O2\"], models=[\"llama_3_2_1b_instruct\", \"llama_3_2_3b_instruct\", \"llama_3_1_8b_instruct\", \"llama_3_1_70b_instruct\", \"qwen_2_5_1p5b_instruct\", \"qwen_2_5_3b_instruct\", \"qwen_2_5_7b_instruct\", \"qwen_2_5_72b_instruct\"])\n",
    "\n",
    "threat_actor_extractor_data = utils.load_json_files(\"./Modules/ThreatActorExtractor/\", [\"Baseline\", \"ZERO-O1\", \"ZERO-O2\", \"FS-O1\", \"FS-O2\"], models=[\"llama_3_2_1b_instruct\", \"llama_3_2_3b_instruct\", \"llama_3_1_8b_instruct\", \"llama_3_1_70b_instruct\", \"qwen_2_5_1p5b_instruct\", \"qwen_2_5_3b_instruct\", \"qwen_2_5_7b_instruct\", \"qwen_2_5_72b_instruct\"])\n",
    "\n",
    "attack_pattern_extractor_data = utils.load_json_files(\"./Modules/AttackPatternExtractor/\", [\"Baseline\", \"ZERO-O1\", \"ZERO-O2\", \"FS-O1\", \"FS-O2\"], models=[\"llama_3_2_1b_instruct\", \"llama_3_2_3b_instruct\", \"llama_3_1_8b_instruct\", \"llama_3_1_70b_instruct\", \"qwen_2_5_1p5b_instruct\", \"qwen_2_5_3b_instruct\", \"qwen_2_5_7b_instruct\", \"qwen_2_5_72b_instruct\"])\n",
    "\n",
    "targets_extractor_data = utils.load_json_files(\"./Modules/TargetsExtractor/\", [\"Baseline\", \"ZERO-O1\", \"ZERO-O2\", \"FS-O1\", \"FS-O2\"], models=[\"llama_3_2_1b_instruct\", \"llama_3_2_3b_instruct\", \"llama_3_1_8b_instruct\", \"llama_3_1_70b_instruct\", \"qwen_2_5_1p5b_instruct\", \"qwen_2_5_3b_instruct\", \"qwen_2_5_7b_instruct\", \"qwen_2_5_72b_instruct\"])\n",
    "\n",
    "\n",
    "\n",
    "def calc_improvements(data: dict):\n",
    "    baseline_f1 = sum(data[\"Baseline\"][\"f1\"])/len(data[\"Baseline\"][\"f1\"])\n",
    "\n",
    "    zs_o1_f1 = sum(data[\"ZERO-O1\"][\"f1\"])/len(data[\"ZERO-O1\"][\"f1\"])\n",
    "    zs_o2_f1 = sum(data[\"ZERO-O2\"][\"f1\"])/len(data[\"ZERO-O2\"][\"f1\"])\n",
    "\n",
    "    fs_o1_f1 = sum(data[\"FS-O1\"][\"f1\"])/len(data[\"FS-O1\"][\"f1\"])\n",
    "    fs_o2_f1 = sum(data[\"FS-O2\"][\"f1\"])/len(data[\"FS-O2\"][\"f1\"])\n",
    "\n",
    "    zs_o1_gain = zs_o1_f1 - baseline_f1\n",
    "    zs_o2_gain = zs_o2_f1 - baseline_f1\n",
    "\n",
    "    fs_o1_gain = fs_o1_f1 - baseline_f1\n",
    "    fs_o2_gain = fs_o2_f1 - baseline_f1\n",
    "\n",
    "\n",
    "    res = {\n",
    "        \"zs_o1_gain\": zs_o1_gain,\n",
    "        \"zs_o2_gain\": zs_o2_gain,\n",
    "        \"fs_o1_gain\": fs_o1_gain,\n",
    "        \"fs_o2_gain\": fs_o2_gain,\n",
    "    }\n",
    "\n",
    "    for key in res.keys():\n",
    "        if res[key] < 0:\n",
    "            res[key] = 0.0\n",
    "\n",
    "    return res\n",
    "\n",
    "\n",
    "\n",
    "gains_by_model = {\n",
    "    \"llama_3_2_1b_instruct\": [],\n",
    "    \"llama_3_2_3b_instruct\": [],\n",
    "    \"llama_3_1_8b_instruct\": [],\n",
    "    \"llama_3_1_70b_instruct\": [],\n",
    "    \"qwen_2_5_1p5b_instruct\": [],\n",
    "    \"qwen_2_5_3b_instruct\": [],\n",
    "    \"qwen_2_5_7b_instruct\": [],\n",
    "    \"qwen_2_5_72b_instruct\": []\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# 1. Malware Extractor \n",
    "for model, value in malware_extractor_data.items():\n",
    "    res = calc_improvements(value)\n",
    "    gains_by_model[model].append(res)\n",
    "    \n",
    "\n",
    "# 2. Threat Actor Extractor \n",
    "for model, value in threat_actor_extractor_data.items():\n",
    "    res = calc_improvements(value)    \n",
    "    gains_by_model[model].append(res)\n",
    "\n",
    "# 3. Attack Pattern Extractor \n",
    "for model, value in attack_pattern_extractor_data.items():\n",
    "    res = calc_improvements(value)    \n",
    "    gains_by_model[model].append(res)\n",
    "\n",
    "# 4. Targets Extractor \n",
    "for model, value in targets_extractor_data.items():\n",
    "    res = calc_improvements(value)    \n",
    "    gains_by_model[model].append(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19ab158a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1e0195ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "llama_llms = [\n",
    "    \"llama_3_2_1b_instruct\",\n",
    "    \"llama_3_2_3b_instruct\",\n",
    "    \"llama_3_1_8b_instruct\",\n",
    "    \"llama_3_1_70b_instruct\",\n",
    "]\n",
    "\n",
    "qwen_llms = [\n",
    "    \"qwen_2_5_1p5b_instruct\",\n",
    "    \"qwen_2_5_3b_instruct\",\n",
    "    \"qwen_2_5_7b_instruct\",\n",
    "    \"qwen_2_5_72b_instruct\"\n",
    "]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "from collections import defaultdict\n",
    "\n",
    "def populate_performances(value):\n",
    "    zs_o1 = np.mean(value[\"ZERO-O1\"][\"f1\"])\n",
    "    zs_o2 = np.mean(value[\"ZERO-O2\"][\"f1\"])\n",
    "    fs_o1 = np.mean(value[\"FS-O1\"][\"f1\"])\n",
    "    fs_o2 = np.mean(value[\"FS-O2\"][\"f1\"])\n",
    "    baseline = np.mean(value[\"Baseline\"][\"f1\"])\n",
    "\n",
    "    if zs_o1 < baseline: \n",
    "        zs_o1 = baseline\n",
    "    \n",
    "    if zs_o2 < baseline:\n",
    "        zs_o2 = baseline\n",
    "    \n",
    "    if fs_o1 < baseline: \n",
    "        fs_o1 = baseline\n",
    "    \n",
    "    if fs_o2 < baseline:\n",
    "        fs_o2 = baseline\n",
    "\n",
    "    return zs_o1, zs_o2, fs_o1, fs_o2, baseline\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# 1. Malware Extractor \n",
    "llama_malware_extractor_delta, qwen_malware_extractor_delta, llama_malware_opt, qwen_malware_opt = defaultdict(list), defaultdict(list), [], []\n",
    "for model, value in malware_extractor_data.items():\n",
    "    zs_o1, zs_o2, fs_o1, fs_o2, baseline = populate_performances(value)\n",
    "    if model in llama_llms:\n",
    "        llama_malware_extractor_delta[\"zs-o1\"].append(zs_o1)\n",
    "        llama_malware_extractor_delta[\"zs-o2\"].append(zs_o2)\n",
    "        llama_malware_extractor_delta[\"fs-o1\"].append(fs_o1)\n",
    "        llama_malware_extractor_delta[\"fs-o2\"].append(fs_o2)\n",
    "        llama_malware_extractor_delta[\"baseline\"].append(baseline)\n",
    "    elif model in qwen_llms:\n",
    "        qwen_malware_extractor_delta[\"zs-o1\"].append(zs_o1)\n",
    "        qwen_malware_extractor_delta[\"zs-o2\"].append(zs_o2)\n",
    "        qwen_malware_extractor_delta[\"fs-o1\"].append(fs_o1)\n",
    "        qwen_malware_extractor_delta[\"fs-o2\"].append(fs_o2)\n",
    "        qwen_malware_extractor_delta[\"baseline\"].append(baseline)\n",
    "    else:\n",
    "        raise Exception(\"Error in qwen_llms or llama_llms for value:\", model)\n",
    "\n",
    "# 2. Threat Actor Extractor \n",
    "llama_actor_delta, qwen_actor_delta, llama_actor_opt, qwen_actor_opt = defaultdict(list), defaultdict(list), [], []\n",
    "for model, value in threat_actor_extractor_data.items():\n",
    "    zs_o1, zs_o2, fs_o1, fs_o2, baseline = populate_performances(value)\n",
    "    if model in llama_llms:\n",
    "        llama_actor_delta[\"zs-o1\"].append(zs_o1)\n",
    "        llama_actor_delta[\"zs-o2\"].append(zs_o2)\n",
    "        llama_actor_delta[\"fs-o1\"].append(fs_o1)\n",
    "        llama_actor_delta[\"fs-o2\"].append(fs_o2)\n",
    "        llama_actor_delta[\"baseline\"].append(baseline)\n",
    "    elif model in qwen_llms:\n",
    "        qwen_actor_delta[\"zs-o1\"].append(zs_o1)\n",
    "        qwen_actor_delta[\"zs-o2\"].append(zs_o2)\n",
    "        qwen_actor_delta[\"fs-o1\"].append(fs_o1)\n",
    "        qwen_actor_delta[\"fs-o2\"].append(fs_o2)\n",
    "        qwen_actor_delta[\"baseline\"].append(baseline)\n",
    "    else:\n",
    "        raise Exception(\"Error in qwen_llms or llama_llms for value:\", model)\n",
    "\n",
    "# 3. Attack Pattern Extractor \n",
    "llama_attack_delta, qwen_attack_delta, llama_attacks_opt, qwen_attacks_opt = defaultdict(list), defaultdict(list), [], []\n",
    "for model, value in attack_pattern_extractor_data.items():\n",
    "    zs_o1, zs_o2, fs_o1, fs_o2, baseline = populate_performances(value)\n",
    "    if model in llama_llms:\n",
    "        llama_attack_delta[\"zs-o1\"].append(zs_o1)\n",
    "        llama_attack_delta[\"zs-o2\"].append(zs_o2)\n",
    "        llama_attack_delta[\"fs-o1\"].append(fs_o1)\n",
    "        llama_attack_delta[\"fs-o2\"].append(fs_o2)\n",
    "        llama_attack_delta[\"baseline\"].append(baseline)\n",
    "    elif model in qwen_llms:\n",
    "        qwen_attack_delta[\"zs-o1\"].append(zs_o1)\n",
    "        qwen_attack_delta[\"zs-o2\"].append(zs_o2)\n",
    "        qwen_attack_delta[\"fs-o1\"].append(fs_o1)\n",
    "        qwen_attack_delta[\"fs-o2\"].append(fs_o2)\n",
    "        qwen_attack_delta[\"baseline\"].append(baseline)\n",
    "    else:\n",
    "        raise Exception(\"Error in qwen_llms or llama_llms for value:\", model)\n",
    "\n",
    "# 4. Targets Extractor \n",
    "llama_targes_delta, qwen_targets_delta, llama_targets_opt, qwen_targets_opt = defaultdict(list), defaultdict(list), [], []\n",
    "for model, value in targets_extractor_data.items():\n",
    "    zs_o1, zs_o2, fs_o1, fs_o2, baseline = populate_performances(value)\n",
    "    if model in llama_llms:\n",
    "        llama_targes_delta[\"zs-o1\"].append(zs_o1)\n",
    "        llama_targes_delta[\"zs-o2\"].append(zs_o2)\n",
    "        llama_targes_delta[\"fs-o1\"].append(fs_o1)\n",
    "        llama_targes_delta[\"fs-o2\"].append(fs_o2)\n",
    "        llama_targes_delta[\"baseline\"].append(baseline)\n",
    "    elif model in qwen_llms:\n",
    "        qwen_targets_delta[\"zs-o1\"].append(zs_o1)\n",
    "        qwen_targets_delta[\"zs-o2\"].append(zs_o2)\n",
    "        qwen_targets_delta[\"fs-o1\"].append(fs_o1)\n",
    "        qwen_targets_delta[\"fs-o2\"].append(fs_o2)\n",
    "        qwen_targets_delta[\"baseline\"].append(baseline)\n",
    "    else:\n",
    "        raise Exception(\"Error in qwen_llms or llama_llms for value:\", model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0091c285",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e08a4565",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Malware Extractor\")\n",
    "for key, value in llama_malware_extractor_delta.items(): \n",
    "    # print(key, \"min:\", min(value), \"max:\", max(value), \"delta\", round((max(value)-min(value))*100, 2))\n",
    "    print(key, round((max(value)-min(value))*100, 2))\n",
    "\n",
    "for key, value in qwen_malware_extractor_delta.items(): \n",
    "    # print(key, \"min:\", min(value), \"max:\", max(value), \"delta\", round((max(value)-min(value))*100, 2))\n",
    "    print(key, round((max(value)-min(value))*100, 2))\n",
    "\n",
    "\n",
    "print(\"Threat Actor\")\n",
    "for key, value in llama_actor_delta.items(): \n",
    "    # print(key, \"min:\", min(value), \"max:\", max(value), \"delta\", round((max(value)-min(value))*100, 2))\n",
    "    print(key, round((max(value)-min(value))*100, 2))\n",
    "\n",
    "\n",
    "for key, value in qwen_actor_delta.items(): \n",
    "    # print(key, \"min:\", min(value), \"max:\", max(value), \"delta\", round((max(value)-min(value))*100, 2))\n",
    "    print(key, round((max(value)-min(value))*100, 2))\n",
    "\n",
    "\n",
    "print(\"Attack Patterns\")\n",
    "for key, value in llama_attack_delta.items(): \n",
    "    # print(key, \"min:\", min(value), \"max:\", max(value), \"delta\", round((max(value)-min(value))*100, 2))\n",
    "    print(key, round((max(value)-min(value))*100, 2))\n",
    "\n",
    "for key, value in qwen_attack_delta.items(): \n",
    "    # print(key, \"min:\", min(value), \"max:\", max(value), \"delta\", round((max(value)-min(value))*100, 2))\n",
    "    print(key, round((max(value)-min(value))*100, 2))\n",
    "\n",
    "\n",
    "print(\"Targets\")\n",
    "for key, value in llama_targes_delta.items(): \n",
    "    # print(key, \"min:\", min(value), \"max:\", max(value), \"delta\", round((max(value)-min(value))*100, 2))\n",
    "    print(key, round((max(value)-min(value))*100, 2))\n",
    "\n",
    "for key, value in qwen_targets_delta.items(): \n",
    "    # print(key, \"min:\", min(value), \"max:\", max(value), \"delta\", round((max(value)-min(value))*100, 2))\n",
    "    print(key, round((max(value)-min(value))*100, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2183c7ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Malware Extractor\")\n",
    "for key, value in qwen_malware_extractor_delta.items(): \n",
    "    print(key, \"min:\", min(value), \"max:\", max(value), \"delta\", round((max(value)-min(value))*100, 2))\n",
    "\n",
    "\n",
    "print(\"Threat Actor\")\n",
    "for key, value in qwen_actor_delta.items(): \n",
    "    print(key, \"min:\", min(value), \"max:\", max(value), \"delta\", round((max(value)-min(value))*100, 2))\n",
    "\n",
    "\n",
    "print(\"Attack Patterns\")\n",
    "for key, value in qwen_attack_delta.items(): \n",
    "    print(key, \"min:\", min(value), \"max:\", max(value), \"delta\", round((max(value)-min(value))*100, 2))\n",
    "\n",
    "\n",
    "print(\"Targets\")\n",
    "for key, value in qwen_targets_delta.items(): \n",
    "    print(key, \"min:\", min(value), \"max:\", max(value), \"delta\", round((max(value)-min(value))*100, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54d24f99",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dcafbbe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c971dcee",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 4, figsize=(10, 3), constrained_layout=True)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "colors = [\"#4074ff\", \"#003bd8\", \"#7d8178\"]\n",
    "bar_count = 3\n",
    "bar_width = 0.05\n",
    "gap = 0.01\n",
    "\n",
    "bar_x = [i * (bar_width + gap) for i in range(bar_count)]\n",
    "\n",
    "\n",
    "# Malware Extractor\n",
    "ax = axs[0]\n",
    "\n",
    "ax.set_ylabel(\"F1-Score\")\n",
    "\n",
    "models = [\"Qwen-72B-ZS-O2\", \"Qwen-72B-FS-O1\", \"aCTIon (GPT 3.5)\"]\n",
    "scores = [79, 81, 72]\n",
    "\n",
    "bars = ax.bar(bar_x, scores, width=bar_width, color=colors)\n",
    "\n",
    "ax.set_title(\"Malware Extractor\", fontsize=13)\n",
    "ax.set_ylim(0, 100)\n",
    "ax.set_xticks(bar_x)\n",
    "ax.set_xticklabels(models, rotation=30, ha='right', fontsize=11)\n",
    "ax.grid(axis='y', linestyle='dashed', linewidth=0.5, alpha=0.4)\n",
    "\n",
    "\n",
    "# Optional: Score\n",
    "for j, bar in enumerate(bars):\n",
    "    ax.text(bar.get_x() + bar.get_width() / 2, bar.get_height() + 1,\n",
    "            str(scores[j]), ha='center', va='bottom', fontsize=8)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Threat Actor Extractor\n",
    "ax = axs[1]\n",
    "models = [\"Llama-70B-ZS-O1\", \"Llama-70B-FS-O1\", \"aCTIon (GPT 3.5)\"]\n",
    "scores = [76, 78, 80]\n",
    "\n",
    "\n",
    "bars = ax.bar(bar_x, scores, width=bar_width, color=colors)\n",
    "\n",
    "ax.set_title(\"Threat-Actor-Extractor\", fontsize=13)\n",
    "ax.set_ylim(0, 100)\n",
    "ax.set_xticks(bar_x)\n",
    "ax.set_xticklabels(models, rotation=30, ha='right', fontsize=11)\n",
    "ax.grid(axis='y', linestyle='dashed', linewidth=0.5, alpha=0.4)\n",
    "\n",
    "\n",
    "# Optional: Score über jedem Balken anzeigen\n",
    "for j, bar in enumerate(bars):\n",
    "    ax.text(bar.get_x() + bar.get_width() / 2, bar.get_height() + 1,\n",
    "            str(scores[j]), ha='center', va='bottom', fontsize=8)\n",
    "\n",
    "\n",
    "# Attack Pattern Extractor\n",
    "ax = axs[2]\n",
    "\n",
    "# ax.set_ylabel(\"F1-Score\")\n",
    "\n",
    "models = [\"Qwen-72B-ZS-O1\", \"Llama-70B-FS-O1\", \"aCTIon (GPT 3.5)\"]\n",
    "scores = [43, 44, 54]\n",
    "\n",
    "bars = ax.bar(bar_x, scores, width=bar_width, color=colors)\n",
    "\n",
    "ax.set_title(\"Attack-Pattern-Extractor\", fontsize=13)\n",
    "ax.set_ylim(0, 100)\n",
    "ax.set_xticks(bar_x)\n",
    "ax.set_xticklabels(models, rotation=30, ha='right', fontsize=11)\n",
    "ax.grid(axis='y', linestyle='dashed', linewidth=0.5, alpha=0.4)\n",
    "\n",
    "\n",
    "# Optional: Score über jedem Balken anzeigen\n",
    "for j, bar in enumerate(bars):\n",
    "    ax.text(bar.get_x() + bar.get_width() / 2, bar.get_height() + 1,\n",
    "            str(scores[j]), ha='center', va='bottom', fontsize=8)\n",
    "    \n",
    "\n",
    "# Targets Extractor\n",
    "ax = axs[3]\n",
    "\n",
    "models = [\"Llama-70B-ZS-O2\", \"Llama-8B-FS-O1\", \"aCTIon (GPT 3.5)\"]\n",
    "scores = [52, 68, 56]\n",
    "\n",
    "\n",
    "bars = ax.bar(bar_x, scores, width=bar_width, color=colors)\n",
    "\n",
    "ax.set_title(\"Targets-Extractor\", fontsize=13)\n",
    "ax.set_ylim(0, 100)\n",
    "ax.set_xticks(bar_x)\n",
    "ax.set_xticklabels(models, rotation=30, ha='right', fontsize=11)\n",
    "\n",
    "ax.grid(axis='y', linestyle='dashed', linewidth=0.5, alpha=0.4)\n",
    "\n",
    "\n",
    "# Optional: Score\n",
    "for j, bar in enumerate(bars):\n",
    "    ax.text(bar.get_x() + bar.get_width() / 2, bar.get_height() + 1,\n",
    "            str(scores[j]), ha='center', va='bottom', fontsize=8)\n",
    "    \n",
    "\n",
    "\n",
    "plt.show()\n",
    "# fig.savefig(\"./pgfs/PerformanceComparisonSOTA.pgf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36a66160",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0559522d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c090421d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ba316af",
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize_model_gains(gains_by_model: dict):\n",
    "    summary = dict()\n",
    "\n",
    "    for model, gains_obj in gains_by_model.items(): \n",
    "        avg_gains = {\n",
    "            \"zs_o1_gain\": 0,\n",
    "            \"zs_o2_gain\": 0,\n",
    "            \"fs_o1_gain\": 0,\n",
    "            \"fs_o2_gain\": 0,\n",
    "        }\n",
    "\n",
    "        for obj in gains_obj:\n",
    "            for key in avg_gains.keys():\n",
    "                avg_gains[key] += obj[key]\n",
    "        \n",
    "\n",
    "        summary[model] = {k: (v / len(gains_obj)) for k, v in avg_gains.items()}\n",
    "\n",
    "    return summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc7967e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "gains_by_llm = summarize_model_gains(gains_by_model)\n",
    "\n",
    "for model, value in gains_by_llm.items(): \n",
    "    print(model, value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4d34d37",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72ed387c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcad0489",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [\n",
    "    \"llama_3_2_1b_instruct\",\n",
    "    \"qwen_2_5_1p5b_instruct\",\n",
    "    \"qwen_2_5_3b_instruct\",\n",
    "    \"llama_3_2_3b_instruct\",\n",
    "    \"qwen_2_5_7b_instruct\",\n",
    "    \"llama_3_1_8b_instruct\",\n",
    "    \"llama_3_1_70b_instruct\",\n",
    "    \"qwen_2_5_72b_instruct\"\n",
    "]\n",
    "\n",
    "\n",
    "zs_o1 = [gains_by_llm[m][\"zs_o1_gain\"] *100 for m in models]\n",
    "zs_o2 = [gains_by_llm[m][\"zs_o2_gain\"] *100 for m in models]\n",
    "fs_o1 = [gains_by_llm[m][\"fs_o1_gain\"] *100 for m in models]\n",
    "fs_o2 = [gains_by_llm[m][\"fs_o2_gain\"] *100 for m in models]\n",
    "\n",
    "fig, ax = plt.subplots(1,1, figsize=(6, 4), layout=\"constrained\")\n",
    "\n",
    "x = np.arange(len(models))\n",
    "width=0.17\n",
    "\n",
    "ax.bar(x - 1.5*width, zs_o1, width, label='ZS-O1', color='blue')\n",
    "ax.bar(x - 0.5*width, zs_o2, width, label='ZS-O2', color='red')\n",
    "\n",
    "ax.bar(x + 0.5*width+0.05, fs_o1, width, label='FS-O1', color='purple')\n",
    "ax.bar(x + 1.5*width+0.05, fs_o2, width, label='FS-O2', color='green')\n",
    "\n",
    "ax.set_xticks(x)\n",
    "models_labels = [\n",
    "    \"Llama 3.2 1B instruct\",\n",
    "    \"Qwen 2.5 1.5B instruct\",\n",
    "    \"Qwen 2.5 3B instruct\",\n",
    "    \"Llama 3.2 3B instruct\",\n",
    "    \"Qwen 2.5 7B instruct\",\n",
    "    \"Llama 3.1 8B instruct\",\n",
    "    \"Llama 3.1 70B instruct\",\n",
    "    \"Qwen 2.5 72B instruct\"\n",
    "]\n",
    "\n",
    "ax.set_xticklabels(models_labels, rotation=30, ha='right', fontsize=10)\n",
    "ax.legend(loc=\"upper right\", prop={'size': 10})\n",
    "\n",
    "\n",
    "plt.grid(axis = \"y\", linestyle=\"dashed\", color=\"gray\", linewidth=0.4, alpha=0.5)\n",
    "\n",
    "ax.set_ylabel(\"Optimizer-Gain (\\%)\")\n",
    "\n",
    "# fig.savefig(\"./pgfs/MetaAvgGainPerLlm.pgf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55b75445",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c73a7c8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "average_gains = {\n",
    "    \"ZS-O1\": np.mean(zs_o1),\n",
    "    \"ZS-O2\": np.mean(zs_o2),\n",
    "    \"FS-O1\": np.mean(fs_o1),\n",
    "    \"FS-O2\": np.mean(fs_o2)\n",
    "}\n",
    "\n",
    "for key, value in average_gains.items():\n",
    "    print(f\"{key}: {value:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12e1a9e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "llama_llms = [\n",
    "    \"llama_3_2_1b_instruct\",\n",
    "    \"llama_3_2_3b_instruct\",\n",
    "    \"llama_3_1_8b_instruct\",\n",
    "    \"llama_3_1_70b_instruct\",\n",
    "]\n",
    "\n",
    "qwen_llms = [\n",
    "    \"qwen_2_5_1p5b_instruct\",\n",
    "    \"qwen_2_5_3b_instruct\",\n",
    "    \"qwen_2_5_7b_instruct\",\n",
    "    \"qwen_2_5_72b_instruct\"\n",
    "]\n",
    "\n",
    "llama_zs_o1_gains = []\n",
    "for llm in llama_llms: \n",
    "    llama_zs_o1_gains.append(gains_by_llm[llm][\"zs_o1_gain\"]*100)\n",
    "\n",
    "qwen_zs_o1_gains = []\n",
    "for llm in qwen_llms: \n",
    "    qwen_zs_o1_gains.append(gains_by_llm[llm][\"zs_o1_gain\"]*100)\n",
    "\n",
    "\n",
    "print(np.mean(llama_zs_o1_gains), np.mean(qwen_zs_o1_gains))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a4b8da1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "408a0d05",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c85d12d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "\n",
    "gains_by_llm = {\n",
    "    'llama_3_2_1b_instruct': {'zs_o1_gain': 0.0405, 'zs_o2_gain': 0.0506, 'fs_o1_gain': 0.2495, 'fs_o2_gain': 0.3001},\n",
    "    'llama_3_2_3b_instruct': {'zs_o1_gain': 0.0781, 'zs_o2_gain': 0.0504, 'fs_o1_gain': 0.2770, 'fs_o2_gain': 0.3417},\n",
    "    'llama_3_1_8b_instruct': {'zs_o1_gain': 0.0079, 'zs_o2_gain': 0.0189, 'fs_o1_gain': 0.1302, 'fs_o2_gain': 0.1244},\n",
    "    'llama_3_1_70b_instruct': {'zs_o1_gain': 0.0382, 'zs_o2_gain': 0.0779, 'fs_o1_gain': 0.1546, 'fs_o2_gain': 0.1493},\n",
    "    'qwen_2_5_1p5b_instruct': {'zs_o1_gain': 0.0540, 'zs_o2_gain': 0.0844, 'fs_o1_gain': 0.2099, 'fs_o2_gain': 0.2591},\n",
    "    'qwen_2_5_3b_instruct': {'zs_o1_gain': 0.0626, 'zs_o2_gain': 0.0817, 'fs_o1_gain': 0.1942, 'fs_o2_gain': 0.1784},\n",
    "    'qwen_2_5_7b_instruct': {'zs_o1_gain': 0.0883, 'zs_o2_gain': 0.1242, 'fs_o1_gain': 0.1877, 'fs_o2_gain': 0.2207},\n",
    "    'qwen_2_5_72b_instruct': {'zs_o1_gain': 0.0815, 'zs_o2_gain': 0.0909, 'fs_o1_gain': 0.1085, 'fs_o2_gain': 0.1402}\n",
    "}\n",
    "\n",
    "models = list(gains_by_llm.keys())\n",
    "zs_o1 = np.array([gains_by_llm[m][\"zs_o1_gain\"] for m in models])\n",
    "zs_o2 = np.array([gains_by_llm[m][\"zs_o2_gain\"] for m in models])\n",
    "fs_o1 = np.array([gains_by_llm[m][\"fs_o1_gain\"] for m in models])\n",
    "fs_o2 = np.array([gains_by_llm[m][\"fs_o2_gain\"] for m in models])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Zero-Shot O1 vs. Few-Shot O1\n",
    "t3, p3 = stats.ttest_rel(zs_o1, fs_o1)\n",
    "print(f\"Zero-Shot O1 vs. Few-Shot O1: t = {t3}, p = {p3}\")\n",
    "\n",
    "# Zero-Shot O2 vs. Few-Shot O2\n",
    "t4, p4 = stats.ttest_rel(zs_o2, fs_o2)\n",
    "print(f\"Zero-Shot O2 vs. Few-Shot O2: t = {t4}, p = {p4}\")\n",
    "\n",
    "# GZero-Shot O1 vs. Zero-Shot O2\n",
    "t_zs, p_zs = stats.ttest_rel(zs_o1, zs_o2)\n",
    "print(f\"Zero-Shot O1 vs. Zero-Shot O2: t = {t_zs}, p = {p_zs}\")\n",
    "\n",
    "# Few-Shot O1 vs. Few-Shot O2\n",
    "t_fs, p_fs = stats.ttest_rel(fs_o1, fs_o2)\n",
    "print(f\"Few-Shot O1 vs. Few-Shot O2: t = {t_fs}, p = {p_fs}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "238c4fc0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "057256fa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26c838af",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "998c49f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "\n",
    "\n",
    "model_sizes = {\n",
    "    \"llama_3_2_1b_instruct\": 1.0,\n",
    "    \"llama_3_2_3b_instruct\": 3.0,\n",
    "    \"llama_3_1_8b_instruct\": 8.0,\n",
    "    # \"llama_3_1_70b_instruct\": 70.0,\n",
    "    \"qwen_2_5_1p5b_instruct\": 1.5,\n",
    "    \"qwen_2_5_3b_instruct\": 3.0,\n",
    "    \"qwen_2_5_7b_instruct\": 7.0,\n",
    "    # \"qwen_2_5_72b_instruct\": 72.0,\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "# scores_by_llm = dict() \n",
    "zs_o1_scores_by_llm, zs_o2_scores_by_llm = dict(), dict()\n",
    "fs_o1_scores_by_llm, fs_o2_scores_by_llm = dict(), dict()\n",
    "\n",
    "\n",
    "for extractor_data in [malware_extractor_data, threat_actor_extractor_data, attack_pattern_extractor_data, targets_extractor_data]:\n",
    "\n",
    "    zs_o1_scores_by_llm, zs_o2_scores_by_llm = dict(), dict()\n",
    "    fs_o1_scores_by_llm, fs_o2_scores_by_llm = dict(), dict()   \n",
    "\n",
    "    for model, value in extractor_data.items(): \n",
    "        # scores_by_llm[model] = np.mean(value[\"Baseline\"][\"f1\"])\n",
    "        zs_o1_scores_by_llm[model] = np.mean(value[\"ZERO-O1\"][\"f1\"])\n",
    "        zs_o2_scores_by_llm[model] = np.mean(value[\"ZERO-O2\"][\"f1\"])\n",
    "\n",
    "        fs_o1_scores_by_llm[model] = np.mean(value[\"FS-O1\"][\"f1\"])\n",
    "        fs_o2_scores_by_llm[model] = np.mean(value[\"FS-O2\"][\"f1\"])\n",
    "\n",
    "\n",
    "    r, p = stats.pearsonr([model_sizes[m] for m in model_sizes.keys()]*2, [zs_o1_scores_by_llm[m] for m in model_sizes.keys()] + [zs_o2_scores_by_llm[m] for m in model_sizes.keys()], alternative=\"greater\")\n",
    "    print(r, p < 0.05, p)\n",
    "\n",
    "\n",
    "    r, p = stats.pearsonr([model_sizes[m] for m in model_sizes.keys()]*2, [fs_o1_scores_by_llm[m] for m in model_sizes.keys()] + [fs_o2_scores_by_llm[m] for m in model_sizes.keys()], alternative=\"greater\")\n",
    "    print(r, p < 0.05, p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b924bece",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97a710e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_sizes_1_to_8 = {\n",
    "    \"llama_3_2_1b_instruct\": 1.0,\n",
    "    \"llama_3_2_3b_instruct\": 3.0,\n",
    "    \"llama_3_1_8b_instruct\": 8.0,\n",
    "    # \"llama_3_1_70b_instruct\": 70.0,\n",
    "    \"qwen_2_5_1p5b_instruct\": 1.5,\n",
    "    \"qwen_2_5_3b_instruct\": 3.0,\n",
    "    \"qwen_2_5_7b_instruct\": 7.0,\n",
    "    # \"qwen_2_5_72b_instruct\": 72.0,\n",
    "}\n",
    "\n",
    "model_sizes_all = {\n",
    "    \"llama_3_2_1b_instruct\": 1.0,\n",
    "    \"llama_3_2_3b_instruct\": 3.0,\n",
    "    \"llama_3_1_8b_instruct\": 8.0,\n",
    "    \"llama_3_1_70b_instruct\": 70.0,\n",
    "    \"qwen_2_5_1p5b_instruct\": 1.5,\n",
    "    \"qwen_2_5_3b_instruct\": 3.0,\n",
    "    \"qwen_2_5_7b_instruct\": 7.0,\n",
    "    \"qwen_2_5_72b_instruct\": 72.0,\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "for type, extractor_data in zip([\"Malware-Extractor\", \"Threat-Actor-Extractor\", \"Attack-Pattern-Extractor\", \"Targets-Extractor\"], [malware_extractor_data, threat_actor_extractor_data, attack_pattern_extractor_data, targets_extractor_data]):\n",
    "    # \n",
    "    baseline_scores_by_llm = dict() \n",
    "    zs_o1_scores_by_llm, zs_o2_scores_by_llm = dict(), dict()\n",
    "    fs_o1_scores_by_llm, fs_o2_scores_by_llm = dict(), dict()   \n",
    "\n",
    "    print(\"\\n++++++++++++++++++++++++++++++++\\n\", type, sep=\"\")\n",
    "\n",
    "    # collect scores for all models \n",
    "    for model, value in extractor_data.items(): \n",
    "        baseline_scores_by_llm[model] = np.mean(value[\"Baseline\"][\"f1\"])\n",
    "\n",
    "        zs_o1_scores_by_llm[model] = np.mean(value[\"ZERO-O1\"][\"f1\"])\n",
    "        zs_o2_scores_by_llm[model] = np.mean(value[\"ZERO-O2\"][\"f1\"])\n",
    "\n",
    "        fs_o1_scores_by_llm[model] = np.mean(value[\"FS-O1\"][\"f1\"])\n",
    "        fs_o2_scores_by_llm[model] = np.mean(value[\"FS-O2\"][\"f1\"])\n",
    "\n",
    "    # calculate correlations \n",
    "    small_r, small_p = stats.pearsonr([model_sizes_1_to_8[m] for m in model_sizes_1_to_8.keys()]*2, [zs_o1_scores_by_llm[m] for m in model_sizes_1_to_8.keys()] + [zs_o2_scores_by_llm[m] for m in model_sizes_1_to_8.keys()], alternative=\"greater\")\n",
    "    \n",
    "    all_r, all_p = stats.pearsonr([model_sizes_all[m] for m in model_sizes_all.keys()]*2, [zs_o1_scores_by_llm[m] for m in model_sizes_all.keys()] + [zs_o2_scores_by_llm[m] for m in model_sizes_all.keys()], alternative=\"greater\")\n",
    "    print(\"Zero-Shot O1/O2:\", np.round(small_r, 3), np.round(small_p, 4), small_p<0.05, \"||\", np.round(all_r, 3), np.round(all_p, 4), all_p<0.05)\n",
    "\n",
    "\n",
    "    small_r, small_p = stats.pearsonr([model_sizes_1_to_8[m] for m in model_sizes_1_to_8.keys()]*2, [fs_o1_scores_by_llm[m] for m in model_sizes_1_to_8.keys()] + [fs_o2_scores_by_llm[m] for m in model_sizes_1_to_8.keys()], alternative=\"greater\")\n",
    "    all_r, all_p = stats.pearsonr([model_sizes_all[m] for m in model_sizes_all.keys()]*2, [fs_o1_scores_by_llm[m] for m in model_sizes_all.keys()] + [fs_o2_scores_by_llm[m] for m in model_sizes_all.keys()], alternative=\"greater\")\n",
    "    print(\"Few-Shot O1/O2:\", np.round(small_r, 3), np.round(small_p, 4), small_p<0.05, \"||\", np.round(all_r, 3), np.round(all_p, 4), all_p<0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7468762a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
